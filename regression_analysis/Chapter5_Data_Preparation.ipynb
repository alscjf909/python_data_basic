{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitdatacentercondac1d4bda37f37481f98de70392cb4ade1",
   "display_name": "Python 3.8.3 64-bit ('datacenter': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric features scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 숫자 특성을 적절하게 조정하고 계수를 비교 및 해석할 뿐만 아니라 비정상적이거나 누락된 값 또는 희소 행렬 처리를 더 쉽게 할 수 있다.  \n",
    "　  \n",
    "* 회귀모델에 의해 허용되고 정확하게 예측될 수 있게 하기 위해 정성적 특성을 숫자값으로 변환한다.  \n",
    "　  \n",
    "* 데이터의 비선형 관계를 선형 관계로 변환할 수 있는 가장 현명한 방법으로 숫자 특성을 변환한다.  \n",
    "　  \n",
    "* 중요한 데이터가 누락될 경우 대체 데이터를 예측하거나 회귀를 통해 자체적으로 최상의 솔루션을 관리하게 하기 위해 수행할 작업을 결정한다.  \n",
    "　  \n",
    "* 데이터의 비정상적이거나 이상한 값을 복구하고 회귀모델을 항상 정상적으로 작동하게 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of data  \n",
    "* 누락된 값을 적극적으로 처리한다.  \n",
    "* 누락된 값에 대해 소극적으로 대처한다.  \n",
    "    - 시스템이 오류를 발생시키고 모든 작업이 중단된다. 문제가 해결될 때까지 중단된 상태를 유지한다.\n",
    "    - 시스템이 누락된 데이터를 무시하고 누락되지 않은 값을 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 편향계수는 예측 변수의 상황이 어떻든 항상 존재하게 된다. 이때 모든 X가 누락된 것과 같은 극단의 경우에도 변수를 표준화하면 0이 된다. 이를 실제로 한번 테스트해보고 여러 최적화기술을 사용해 누락된 값을 고정하기 위해 ** 예측변수를 조정하는 방법과 변칙적인 값을 쉽게 감지 할 수 있는 방법을 알아보자.**  \n",
    "마크다운 문법`<u> </u>` 안먹힘... 쓰지마세여..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "np.set_printoptions(precision=5, suppress=True) # 소수점 출력을 5자리 숫자로 설정한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보스턴 데이터 셋 다시 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston() \n",
    "dataset = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "dataset['target'] = boston.target\n",
    "observations = len(dataset)\n",
    "variables = dataset.columns[:-1]\n",
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀에 대해서 테스토 하고자 하기때문에 25이상의 모든 값에 대해 목표변수를 이진 응답으로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yq = np.array(y>25, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric features scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수 StandardScalar와 MinMaxScalar를 사용한다. 두가지 전부 파라미터를 기록하고 저장하는 fit메소드를 갖는다.  \n",
    "StandardScalar 클래스 : 평균이 0과 표준편차가 1이 되도록 변환  \n",
    "MinMaxScaler 클래스 : 최대값이 각각 1, 최소값이 0 되도록 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "coefficients: [ -0.10801   0.04642   0.02056   2.68673 -17.76661   3.80987   0.00069\n  -1.47557   0.30605  -0.01233  -0.95275   0.00931  -0.52476]\nintercept: 36.459\n"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "linear_regression = linear_model.LinearRegression(normalize=False, fit_intercept=True)\n",
    "linear_regression.fit(X,y)\n",
    "print (\"coefficients: %s\\nintercept: %0.3f\" % (linear_regression.coef_,linear_regression.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "CRIM         0.00632\nZN           0.00000\nINDUS        0.46000\nCHAS         0.00000\nNOX          0.38500\nRM           3.56100\nAGE          2.90000\nDIS          1.12960\nRAD          1.00000\nTAX        187.00000\nPTRATIO     12.60000\nB            0.32000\nLSTAT        1.73000\ntarget       5.00000\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "dataset.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![캡처](img5/캡처.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) StandardScaler  \n",
    "\n",
    "각 feature의 평균을 0, 분산을 1로 변경합니다. 모든 특성들이 같은 스케일을 갖게 됩니다.  \n",
    "\n",
    "\n",
    "\n",
    "(2) RobustScaler  \n",
    "\n",
    "모든 특성들이 같은 크기를 갖는다는 점에서 StandardScaler와 비슷하지만, 평균과 분산 대신 median과 quartile을 사용합니다. RobustScaler는 이상치에 영향을 받지 않습니다.  \n",
    "\n",
    "\n",
    "\n",
    "(3) MinMaxScaler  \n",
    "\n",
    "모든 feature가 0과 1사이에 위치하게 만듭니다.  \n",
    "\n",
    "데이터가 2차원 셋일 경우, 모든 데이터는 x축의 0과 1 사이에, y축의 0과 1사이에 위치하게 됩니다.  \n",
    "\n",
    "\n",
    "\n",
    "(4) Normalizer  \n",
    "\n",
    "StandardScaler, RobustScaler, MinMaxScaler가 각 columns의 통계치를 이용한다면 Normalizer는 row마다 각각 정규화됩니다. Normalizer는 유클리드 거리가 1이 되도록 데이터를 조정합니다. (유클리드 거리는 두 점 사이의 거리를 계산할 때 쓰는 방법, L2 Distance)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Centering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 조정 작업에서 변수를 중심에 놓고 진행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "coefficients: [ -0.10801   0.04642   0.02056   2.68673 -17.76661   3.80987   0.00069\n  -1.47557   0.30605  -0.01233  -0.95275   0.00931  -0.52476]\nintercept: 22.533\n"
    }
   ],
   "source": [
    "centering = StandardScaler(with_mean=True, with_std=False)\n",
    "linear_regression.fit(centering.fit_transform(X),y)\n",
    "print (\"coefficients: %s\\nintercept: %0.3f\" % (linear_regression.coef_,linear_regression.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mean: 22.533\n"
    }
   ],
   "source": [
    "print('mean: %0.3f' % np.mean(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단위 분산에 맞게 모든 것을 조정하고 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "coefficients: [-0.92815  1.08157  0.1409   0.68174 -2.05672  2.67423  0.01947 -3.10404\n  2.66222 -2.07678 -2.06061  0.84927 -3.74363]\nintercept: 22.533\n"
    }
   ],
   "source": [
    "standardization = StandardScaler(with_mean=True, with_std=True)\n",
    "linear_regression.fit(standardization.fit_transform(X),y)\n",
    "print (\"coefficients: %s\\nintercept: %0.3f\" % (linear_regression.coef_,linear_regression.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "coefficients: [ -9.60976   4.64205   0.56084   2.68673  -8.63457  19.88369   0.06722\n -16.22666   7.03914  -6.46333  -8.95582   3.69283 -19.01724]\nintercept: 26.620\n"
    }
   ],
   "source": [
    "scaling  = MinMaxScaler(feature_range=(0, 1))\n",
    "linear_regression.fit(scaling.fit_transform(X),y)\n",
    "print (\"coefficients: %s\\nintercept: %0.3f\" % (linear_regression.coef_,linear_regression.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Optimization terminated successfully.\n         Current function value: 0.206631\n         Iterations 9\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                      y   No. Observations:                  506\nModel:                          Logit   Df Residuals:                      492\nMethod:                           MLE   Df Model:                           13\nDate:                Mon, 10 Aug 2020   Pseudo R-squ.:                  0.6289\nTime:                        18:14:00   Log-Likelihood:                -104.56\nconverged:                       True   LL-Null:                       -281.76\nCovariance Type:            nonrobust   LLR p-value:                 9.145e-68\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -3.0542      0.356     -8.571      0.000      -3.753      -2.356\nx1            -0.0954      0.390     -0.245      0.807      -0.859       0.668\nx2             0.2544      0.252      1.008      0.314      -0.240       0.749\nx3            -0.7570      0.403     -1.880      0.060      -1.546       0.032\nx4             0.2452      0.205      1.195      0.232      -0.157       0.648\nx5            -0.7923      0.519     -1.527      0.127      -1.810       0.225\nx6             1.3244      0.318      4.168      0.000       0.702       1.947\nx7             0.0982      0.313      0.314      0.754      -0.515       0.712\nx8            -1.2391      0.345     -3.591      0.000      -1.915      -0.563\nx9             2.7665      0.719      3.849      0.000       1.358       4.175\nx10           -1.8228      0.680     -2.682      0.007      -3.155      -0.491\nx11           -0.7635      0.264     -2.887      0.004      -1.282      -0.245\nx12           -0.2065      0.349     -0.592      0.554      -0.891       0.478\nx13           -2.6207      0.521     -5.031      0.000      -3.642      -1.600\n==============================================================================\n"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "Xq = sm.add_constant(standardization.fit_transform(X))\n",
    "logit = sm.Logit(yq,Xq)\n",
    "result = logit.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱회귀에서 예측변수의 단위 변화는 계수 자체의 지수에 해당하는 양의 응답 오즈비를 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "odd ratios of coefficients : [ 0.04716  0.90902  1.28964  0.46908  1.27788  0.45278  3.76007  1.10314\n  0.28965 15.90341  0.16158  0.46603  0.81345  0.07275]\n"
    }
   ],
   "source": [
    "print('odd ratios of coefficients : %s' % np.exp(result.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "intercept: -3.054\nprobability of value above 25 when all predictors are average : 0.045\n"
    }
   ],
   "source": [
    "def sigmoid(p):\n",
    "    return 1 / (1+np.exp(-p))\n",
    "print('intercept: %0.3f'%result.params[0])\n",
    "print('probability of value above 25 when all predictors are average : %0.3f' %sigmoid(result.params[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}