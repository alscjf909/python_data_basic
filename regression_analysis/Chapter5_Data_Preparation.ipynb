{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitdatacentercondac1d4bda37f37481f98de70392cb4ade1",
   "display_name": "Python 3.8.3 64-bit ('datacenter': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric features scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 숫자 특성을 적절하게 조정하고 계수를 비교 및 해석할 뿐만 아니라 비정상적이거나 누락된 값 또는 희소 행렬 처리를 더 쉽게 할 수 있다.  \n",
    "　  \n",
    "* 회귀모델에 의해 허용되고 정확하게 예측될 수 있게 하기 위해 정성적 특성을 숫자값으로 변환한다.  \n",
    "　  \n",
    "* 데이터의 비선형 관계를 선형 관계로 변환할 수 있는 가장 현명한 방법으로 숫자 특성을 변환한다.  \n",
    "　  \n",
    "* 중요한 데이터가 누락될 경우 대체 데이터를 예측하거나 회귀를 통해 자체적으로 최상의 솔루션을 관리하게 하기 위해 수행할 작업을 결정한다.  \n",
    "　  \n",
    "* 데이터의 비정상적이거나 이상한 값을 복구하고 회귀모델을 항상 정상적으로 작동하게 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of data  \n",
    "* 누락된 값을 적극적으로 처리한다.  \n",
    "* 누락된 값에 대해 소극적으로 대처한다.  \n",
    "    - 시스템이 오류를 발생시키고 모든 작업이 중단된다. 문제가 해결될 때까지 중단된 상태를 유지한다.\n",
    "    - 시스템이 누락된 데이터를 무시하고 누락되지 않은 값을 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 편향계수는 예측 변수의 상황이 어떻든 항상 존재하게 된다. 이때 모든 X가 누락된 것과 같은 극단의 경우에도 변수를 표준화하면 0이 된다. 이를 실제로 한번 테스트해보고 여러 최적화기술을 사용해 누락된 값을 고정하기 위해 ** 예측변수를 조정하는 방법과 변칙적인 값을 쉽게 감지 할 수 있는 방법을 알아보자.**  \n",
    "마크다운 문법`<u> </u>` 안먹힘... 쓰지마세여..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "np.set_printoptions(precision=5, suppress=True) # 소수점 출력을 5자리 숫자로 설정한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보스턴 데이터 셋 다시 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston() \n",
    "dataset = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "dataset['target'] = boston.target\n",
    "observations = len(dataset)\n",
    "variables = dataset.columns[:-1]\n",
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀에 대해서 테스토 하고자 하기때문에 25이상의 모든 값에 대해 목표변수를 이진 응답으로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yq = np.array(y>25, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric features scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수 StandardScalar와 MinMaxScalar를 사용한다. 두가지 전부 파라미터를 기록하고 저장하는 fit메소드를 갖는다.  \n",
    "StandardScalar 클래스 : 평균이 0과 표준편차가 1이 되도록 변환  \n",
    "MinMaxScaler 클래스 : 최대값이 각각 1, 최소값이 0 되도록 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "coefficients: [ -0.10801   0.04642   0.02056   2.68673 -17.76661   3.80987   0.00069\n  -1.47557   0.30605  -0.01233  -0.95275   0.00931  -0.52476]\nintercept: 36.459\n"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "linear_regression = linear_model.LinearRegression(normalize=False, fit_intercept=True)\n",
    "linear_regression.fit(X,y)\n",
    "print (\"coefficients: %s\\nintercept: %0.3f\" % (linear_regression.coef_,linear_regression.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "CRIM         0.00632\nZN           0.00000\nINDUS        0.46000\nCHAS         0.00000\nNOX          0.38500\nRM           3.56100\nAGE          2.90000\nDIS          1.12960\nRAD          1.00000\nTAX        187.00000\nPTRATIO     12.60000\nB            0.32000\nLSTAT        1.73000\ntarget       5.00000\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "dataset.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![캡처](img5/캡처.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) StandardScaler  \n",
    "\n",
    "각 feature의 평균을 0, 분산을 1로 변경합니다. 모든 특성들이 같은 스케일을 갖게 됩니다.  \n",
    "\n",
    "\n",
    "\n",
    "(2) RobustScaler  \n",
    "\n",
    "모든 특성들이 같은 크기를 갖는다는 점에서 StandardScaler와 비슷하지만, 평균과 분산 대신 median과 quartile을 사용합니다. RobustScaler는 이상치에 영향을 받지 않습니다.  \n",
    "\n",
    "\n",
    "\n",
    "(3) MinMaxScaler  \n",
    "\n",
    "모든 feature가 0과 1사이에 위치하게 만듭니다.  \n",
    "\n",
    "데이터가 2차원 셋일 경우, 모든 데이터는 x축의 0과 1 사이에, y축의 0과 1사이에 위치하게 됩니다.  \n",
    "\n",
    "\n",
    "\n",
    "(4) Normalizer  \n",
    "\n",
    "StandardScaler, RobustScaler, MinMaxScaler가 각 columns의 통계치를 이용한다면 Normalizer는 row마다 각각 정규화됩니다. Normalizer는 유클리드 거리가 1이 되도록 데이터를 조정합니다. (유클리드 거리는 두 점 사이의 거리를 계산할 때 쓰는 방법, L2 Distance)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Centering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 조정 작업에서 변수를 중심에 놓고 진행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "coefficients: [ -0.10801   0.04642   0.02056   2.68673 -17.76661   3.80987   0.00069\n  -1.47557   0.30605  -0.01233  -0.95275   0.00931  -0.52476]\nintercept: 22.533\n"
    }
   ],
   "source": [
    "centering = StandardScaler(with_mean=True, with_std=False)\n",
    "linear_regression.fit(centering.fit_transform(X),y)\n",
    "print (\"coefficients: %s\\nintercept: %0.3f\" % (linear_regression.coef_,linear_regression.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mean: 22.533\n"
    }
   ],
   "source": [
    "print('mean: %0.3f' % np.mean(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단위 분산에 맞게 모든 것을 조정하고 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "coefficients: [-0.92815  1.08157  0.1409   0.68174 -2.05672  2.67423  0.01947 -3.10404\n  2.66222 -2.07678 -2.06061  0.84927 -3.74363]\nintercept: 22.533\n"
    }
   ],
   "source": [
    "standardization = StandardScaler(with_mean=True, with_std=True)\n",
    "linear_regression.fit(standardization.fit_transform(X),y)\n",
    "print (\"coefficients: %s\\nintercept: %0.3f\" % (linear_regression.coef_,linear_regression.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "coefficients: [ -9.60976   4.64205   0.56084   2.68673  -8.63457  19.88369   0.06722\n -16.22666   7.03914  -6.46333  -8.95582   3.69283 -19.01724]\nintercept: 26.620\n"
    }
   ],
   "source": [
    "scaling  = MinMaxScaler(feature_range=(0, 1))\n",
    "linear_regression.fit(scaling.fit_transform(X),y)\n",
    "print (\"coefficients: %s\\nintercept: %0.3f\" % (linear_regression.coef_,linear_regression.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The logistic regression case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Optimization terminated successfully.\n         Current function value: 0.206631\n         Iterations 9\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                      y   No. Observations:                  506\nModel:                          Logit   Df Residuals:                      492\nMethod:                           MLE   Df Model:                           13\nDate:                Tue, 11 Aug 2020   Pseudo R-squ.:                  0.6289\nTime:                        17:05:51   Log-Likelihood:                -104.56\nconverged:                       True   LL-Null:                       -281.76\nCovariance Type:            nonrobust   LLR p-value:                 9.145e-68\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -3.0542      0.356     -8.571      0.000      -3.753      -2.356\nx1            -0.0954      0.390     -0.245      0.807      -0.859       0.668\nx2             0.2544      0.252      1.008      0.314      -0.240       0.749\nx3            -0.7570      0.403     -1.880      0.060      -1.546       0.032\nx4             0.2452      0.205      1.195      0.232      -0.157       0.648\nx5            -0.7923      0.519     -1.527      0.127      -1.810       0.225\nx6             1.3244      0.318      4.168      0.000       0.702       1.947\nx7             0.0982      0.313      0.314      0.754      -0.515       0.712\nx8            -1.2391      0.345     -3.591      0.000      -1.915      -0.563\nx9             2.7665      0.719      3.849      0.000       1.358       4.175\nx10           -1.8228      0.680     -2.682      0.007      -3.155      -0.491\nx11           -0.7635      0.264     -2.887      0.004      -1.282      -0.245\nx12           -0.2065      0.349     -0.592      0.554      -0.891       0.478\nx13           -2.6207      0.521     -5.031      0.000      -3.642      -1.600\n==============================================================================\n"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "Xq = sm.add_constant(standardization.fit_transform(X))\n",
    "logit = sm.Logit(yq,Xq)\n",
    "result = logit.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱회귀에서 예측변수의 단위 변화는 계수 자체의 지수에 해당하는 양의 응답 오즈비를 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "odd ratios of coefficients : [ 0.04716  0.90902  1.28964  0.46908  1.27788  0.45278  3.76007  1.10314\n  0.28965 15.90341  0.16158  0.46603  0.81345  0.07275]\n"
    }
   ],
   "source": [
    "print('odd ratios of coefficients : %s' % np.exp(result.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[오즈비 및 Signoid 설명](https://www.notion.so/Activation-Sigmoid-a866210cc04d488b8c96e09c9ee49228)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "intercept: -3.054\nprobability of value above 25 when all predictors are average : 0.045\n"
    }
   ],
   "source": [
    "def sigmoid(p):\n",
    "    return 1 / (1+np.exp(-p))\n",
    "print('intercept: %0.3f'%result.params[0])\n",
    "print('probability of value above 25 when all predictors are average : %0.3f' %sigmoid(result.params[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시그모이드 함수를 사용해 절편을 확률로 변환하면 값 0.045를 얻을 수 있다. 이 값은 예측변수가 평균값을 가질 때 주택 가격이 25보다 클확률이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "average likelihood of positive response: 0.245\n"
    }
   ],
   "source": [
    "print ('average likelihood of positive response: %0.3f' % (sum(yq) / float(len(yq))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Optimization terminated successfully.\n         Current function value: 0.556842\n         Iterations 5\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                      y   No. Observations:                  506\nModel:                          Logit   Df Residuals:                      505\nMethod:                           MLE   Df Model:                            0\nDate:                Tue, 11 Aug 2020   Pseudo R-squ.:               3.276e-11\nTime:                        17:05:51   Log-Likelihood:                -281.76\nconverged:                       True   LL-Null:                       -281.76\nCovariance Type:            nonrobust   LLR p-value:                       nan\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -1.1251      0.103    -10.886      0.000      -1.328      -0.923\n==============================================================================\n\nprobability of value above 25 using just a constant: 0.245\n"
    }
   ],
   "source": [
    "C = np.ones(len(X))\n",
    "logit = sm.Logit(yq, C)\n",
    "result = logit.fit()\n",
    "print (result.summary())\n",
    "print ('\\nprobability of value above 25 using just a constant: %0.3f' % sigmoid(result.params[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 추출한 것은 특정 확률을 통해 추출 한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative features encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 정성적 변수를 이용하여 데이터를 분석하였다. 하지만 데이터에는 정성적 조건을 안가지고 있을 수도 있다. 이를 정성적인 변환하여 데이터셋을 활용하여 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlook     = ['sunny', 'overcast', 'rainy']\n",
    "temperature = ['hot', 'mild', 'cool']\n",
    "humidity    = ['high', 'normal']\n",
    "windy       = ['TRUE', 'FALSE']\n",
    "\n",
    "weather_dataset = list()\n",
    "\n",
    "for o in outlook:\n",
    "    for t in temperature:\n",
    "        for h in humidity:\n",
    "            for w in windy:\n",
    "                weather_dataset.append([o,t,h,w])\n",
    "\n",
    "play = [0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1대 1 데이터 셋 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-00cf07b74dcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일련의 정성적 변수를 이진변수로 변환하는 가장 빠른 방법은 pandas를 사용하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(weather_dataset, columns=['outlook', 'temperature', 'humidity', 'windy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   overcast  rainy  sunny\n0         0      0      1\n1         0      0      1\n2         0      0      1\n3         0      0      1\n4         0      0      1\n5         0      0      1\n6         0      0      1\n7         0      0      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overcast</th>\n      <th>rainy</th>\n      <th>sunny</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(pd.get_dummies(df.outlook).iloc[:8,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_dummies(df)` 데이터들을 이진분류로 나누어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_encoding = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`statsmodels.api`를 황용해 상관계수 구하고 분석 시작!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Optimization terminated successfully.\n         Current function value: 0.292346\n         Iterations 28\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                      y   No. Observations:                   36\nModel:                          Logit   Df Residuals:                       29\nMethod:                           MLE   Df Model:                            6\nDate:                Tue, 11 Aug 2020   Pseudo R-squ.:                  0.5744\nTime:                        17:05:51   Log-Likelihood:                -10.524\nconverged:                       True   LL-Null:                       -24.731\nCovariance Type:            nonrobust   LLR p-value:                 7.856e-05\n====================================================================================\n                       coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------------\nconst                0.2393    4.3e+07   5.57e-09      1.000   -8.42e+07    8.42e+07\noutlook_overcast     2.9833   5.09e+07   5.86e-08      1.000   -9.98e+07    9.98e+07\noutlook_rainy       -2.1746   5.04e+07  -4.31e-08      1.000   -9.88e+07    9.88e+07\noutlook_sunny       -0.5695   4.99e+07  -1.14e-08      1.000   -9.77e+07    9.77e+07\ntemperature_cool    -2.1996   4.66e+07  -4.72e-08      1.000   -9.13e+07    9.13e+07\ntemperature_hot      0.3045   4.65e+07   6.54e-09      1.000   -9.12e+07    9.12e+07\ntemperature_mild     2.1344   4.67e+07   4.57e-08      1.000   -9.15e+07    9.15e+07\nhumidity_high       -2.0459   6.08e+06  -3.36e-07      1.000   -1.19e+07    1.19e+07\nhumidity_normal      2.2851   6.63e+06   3.45e-07      1.000    -1.3e+07     1.3e+07\nwindy_FALSE          1.3162        nan        nan        nan         nan         nan\nwindy_TRUE          -1.0770        nan        nan        nan         nan         nan\n====================================================================================\n"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(dummy_encoding)\n",
    "logit = sm.Logit(play, X)\n",
    "result = logit.fit()\n",
    "print (result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완벽한 공선성을 안좋아하는 경우도 있어 이진변수 집합에서 선택한 수준만 삭제하기만 하면 된다. 그렇게 되면 제거된 계수는 절편으로 통합되고 회귀모델은 다른변수와 계수를 사용해 이전처럼 작동할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Optimization terminated successfully.\n         Current function value: 0.292346\n         Iterations 8\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                      y   No. Observations:                   36\nModel:                          Logit   Df Residuals:                       29\nMethod:                           MLE   Df Model:                            6\nDate:                Tue, 11 Aug 2020   Pseudo R-squ.:                  0.5744\nTime:                        17:05:51   Log-Likelihood:                -10.524\nconverged:                       True   LL-Null:                       -24.731\nCovariance Type:            nonrobust   LLR p-value:                 7.856e-05\n====================================================================================\n                       coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------------\nconst                5.4055      2.196      2.462      0.014       1.102       9.709\noutlook_overcast     3.5528      1.721      2.064      0.039       0.179       6.927\noutlook_rainy       -1.6051      1.357     -1.183      0.237      -4.265       1.055\ntemperature_cool    -4.3340      1.867     -2.322      0.020      -7.993      -0.675\ntemperature_hot     -1.8299      1.478     -1.238      0.216      -4.727       1.067\nhumidity_high       -4.3310      1.645     -2.633      0.008      -7.555      -1.107\nwindy_TRUE          -2.3932      1.325     -1.807      0.071      -4.989       0.203\n====================================================================================\n"
    }
   ],
   "source": [
    "X.drop(['outlook_sunny', 'temperature_mild', 'humidity_normal', 'windy_FALSE'], inplace=True, axis=1)\n",
    "logit = sm.Logit(play, X)\n",
    "result = logit.fit()\n",
    "print (result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn 패키지에서 정성적 변수를 숫자 변수로 일관되게 변환 하는 방법을 제공한다. 그 중 One-hot encoding을 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'outlook': 'sunny', 'temperature': 'hot', 'humidity': 'high', 'windy': 'TRUE'}\n[[1. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n [1. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n [0. 1. 0. 0. 1. 0. 1. 0. 0. 1.]\n [0. 1. 0. 0. 1. 0. 1. 0. 1. 0.]\n [1. 0. 0. 0. 1. 0. 0. 1. 0. 1.]\n [1. 0. 0. 0. 1. 0. 0. 1. 1. 0.]\n [0. 1. 0. 0. 1. 0. 0. 1. 0. 1.]\n [0. 1. 0. 0. 1. 0. 0. 1. 1. 0.]\n [1. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n [1. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n [0. 1. 0. 0. 1. 1. 0. 0. 0. 1.]\n [0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n [1. 0. 1. 0. 0. 0. 1. 0. 0. 1.]\n [1. 0. 1. 0. 0. 0. 1. 0. 1. 0.]\n [0. 1. 1. 0. 0. 0. 1. 0. 0. 1.]\n [0. 1. 1. 0. 0. 0. 1. 0. 1. 0.]\n [1. 0. 1. 0. 0. 0. 0. 1. 0. 1.]\n [1. 0. 1. 0. 0. 0. 0. 1. 1. 0.]\n [0. 1. 1. 0. 0. 0. 0. 1. 0. 1.]\n [0. 1. 1. 0. 0. 0. 0. 1. 1. 0.]\n [1. 0. 1. 0. 0. 1. 0. 0. 0. 1.]\n [1. 0. 1. 0. 0. 1. 0. 0. 1. 0.]\n [0. 1. 1. 0. 0. 1. 0. 0. 0. 1.]\n [0. 1. 1. 0. 0. 1. 0. 0. 1. 0.]\n [1. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n [1. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n [0. 1. 0. 1. 0. 0. 1. 0. 0. 1.]\n [0. 1. 0. 1. 0. 0. 1. 0. 1. 0.]\n [1. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n [1. 0. 0. 1. 0. 0. 0. 1. 1. 0.]\n [0. 1. 0. 1. 0. 0. 0. 1. 0. 1.]\n [0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]\n [1. 0. 0. 1. 0. 1. 0. 0. 0. 1.]\n [1. 0. 0. 1. 0. 1. 0. 0. 1. 0.]\n [0. 1. 0. 1. 0. 1. 0. 0. 0. 1.]\n [0. 1. 0. 1. 0. 1. 0. 0. 1. 0.]]\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'vectorzier' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-96f471017dba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_representation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_representation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mvect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvectorzier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_representation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorzier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse = False)\n",
    "dict_representation = [{varname:var for var, varname in zip(row,['outlook', 'temperature', 'humidity', 'windy'])} for row in weather_dataset]\n",
    "print(dict_representation[0])\n",
    "print(vectorizer.fit_transform(dict_representation))\n",
    "vect=vectorzier.fit_transform(dict_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DictVectorizer 으로 불러오때 안에서 sort한다음 불러옴 그래서 abc순서대로 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['humidity=high', 'humidity=normal', 'outlook=overcast', 'outlook=rainy', 'outlook=sunny', 'temperature=cool', 'temperature=hot', 'temperature=mild', 'windy=FALSE', 'windy=TRUE']\n"
    }
   ],
   "source": [
    "print(vectorizer.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1]\n"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "label_encoder = LabelEncoder()\n",
    "print (label_encoder.fit_transform(df.outlook)) # 라벨 값 숫자로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['overcast', 'rainy', 'sunny'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "label_encoder.inverse_transform([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['overcast' 'rainy' 'sunny']\n"
    }
   ],
   "source": [
    "print (label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0 0 1]\n [0 0 1]\n [0 0 1]\n [0 0 1]\n [0 0 1]\n [0 0 1]\n [0 0 1]\n [0 0 1]\n [0 0 1]\n [0 0 1]\n [0 0 1]\n [0 0 1]\n [1 0 0]\n [1 0 0]\n [1 0 0]\n [1 0 0]\n [1 0 0]\n [1 0 0]\n [1 0 0]\n [1 0 0]\n [1 0 0]\n [1 0 0]\n [1 0 0]\n [1 0 0]\n [0 1 0]\n [0 1 0]\n [0 1 0]\n [0 1 0]\n [0 1 0]\n [0 1 0]\n [0 1 0]\n [0 1 0]\n [0 1 0]\n [0 1 0]\n [0 1 0]\n [0 1 0]]\n"
    }
   ],
   "source": [
    "label_binarizer = LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\n",
    "print (label_binarizer.fit_transform(label_encoder.fit_transform(df.outlook)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Hasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'헤헤': 0, '재밌다': 1, '짱짱': 2, '맨': 3, '김민철': 4, '짱': 5}\n"
    }
   ],
   "source": [
    "your_text = '김민철 짱 짱 짱 짱 짱 짱 짱짱 맨 헤헤 재밌다'\n",
    "mapping_words_in_text = {word:position for position, word in enumerate(set(your_text.lower().split(' ')))} # enumerate() 자료형을 입력으로 받아 인덱스 값을 포함하는 enumerate 객체를 리턴\n",
    "# set() 집합에 관련된 것을 쉽게 처리하기 위해 만든 자료형 동일한 것은 제외함 중복 허용 x\n",
    "print (mapping_words_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 body\n1 body\n2 foo\n"
    }
   ],
   "source": [
    "for i, name in enumerate(['body', 'body', 'foo']):\n",
    "    print(i,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}